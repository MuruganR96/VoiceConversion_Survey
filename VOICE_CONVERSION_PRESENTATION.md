# Voice Conversion: M2F & F2M
## Complete Survey - DSP, ML Edge & GPU Server Approaches

**Author**: Murugan R
**Date**: January 2026
**Repository**: https://github.com/MuruganR96/VoiceConversion_Survey

---

# Table of Contents

1. Introduction & Overview
2. **Aspect 1**: DSP-Based Approaches (Edge)
3. **Aspect 2**: ML/DL Edge Deployment (â‰¤2MB)
4. **Aspect 3**: GPU Server State-of-the-Art
5. Comparison & Recommendations
6. Deployment Scenarios
7. Conclusion

---

# Introduction

## Voice Conversion Goals

**Objective**: Transform voice characteristics while preserving linguistic content

- **Male-to-Female (M2F)**: Male voice â†’ Female voice
- **Female-to-Male (F2M)**: Female voice â†’ Male voice

**Key Requirements**:
- Preserve speech content (what is said)
- Change speaker identity (who says it)
- Maintain naturalness

---

# Three Deployment Aspects

## Complete Coverage

| Aspect | Platform | Memory | Target Use Case |
|--------|----------|--------|-----------------|
| **1. DSP** | CPU | <1MB | Mobile, IoT, Embedded |
| **2. ML Edge** | CPU | â‰¤2MB | Edge devices, Real-time |
| **3. GPU Server** | GPU | 50MB-1GB | Cloud APIs, High quality |

---

# ASPECT 1: DSP-Based Approaches
## CPU-Only, Lightweight, Real-Time

---

# DSP Overview

## Digital Signal Processing Methods

**Advantages**:
- âœ… No training data required
- âœ… Lightweight (<1MB)
- âœ… Real-time capable
- âœ… Deterministic
- âœ… Interpretable

**Limitations**:
- âš ï¸ Lower quality than deep learning
- âš ï¸ May produce artifacts
- âš ï¸ Requires parameter tuning

---

# Model 1: WORLD Vocoder â­

## High-Quality Speech Vocoder

**Description**: Analysis/synthesis system separating F0, spectral envelope, and aperiodicity

**Repository**: https://github.com/mmorise/World

**License**: BSD-3-Clause

---

# WORLD Vocoder - Specifications

| Metric | Value | Status |
|--------|-------|--------|
| **Memory (C++)** | ~1MB | âœ… Excellent |
| **Memory (Python)** | ~5-10MB | âš ï¸ Overhead |
| **Latency** | 50-150ms | âœ… Real-time |
| **RTF** | 0.3-0.5 | âœ… Fast |
| **Quality (MOS)** | 3.5-4.0 | âœ… Good |
| **Platform** | Cross-platform | âœ… |

**RTF** = Real-Time Factor (<1.0 = faster than real-time)

---

# WORLD Vocoder - How It Works

## Three-Step Process

**1. Analysis**:
- Extract F0 (pitch): 80-300 Hz
- Extract spectral envelope (formants)
- Extract aperiodicity (breathiness)

**2. Modification**:
- M2F: F0 Ã—1.6, Formants Ã—1.2
- F2M: F0 Ã—0.65, Formants Ã—0.85

**3. Synthesis**:
- Reconstruct modified speech

---

# WORLD Vocoder - Advantages

## âœ… Strengths

1. **High Quality**: Near-transparent reconstruction
2. **Independent Control**: F0, formants, aperiodicity separately
3. **Well-Documented**: Extensive research (IEICE 2016)
4. **Production-Ready**: Used in industry
5. **Fast**: 3-5Ã— real-time on CPU
6. **No Training**: Works immediately
7. **Cross-Platform**: Windows, Linux, macOS, embedded

---

# WORLD Vocoder - Disadvantages

## âš ï¸ Limitations

1. **Moderate Quality**: Not as good as deep learning
2. **Parameter Tuning**: Requires expertise
3. **Artifacts**: May produce robotic sound
4. **Manual Optimization**: No automatic learning
5. **Python Overhead**: Native C++ needed for <2MB

**Recommendation**: Best for edge/embedded deployment

---

# Model 2: PSOLA

## Pitch Synchronous Overlap-Add

**Description**: Time-domain pitch modification technique

**Repository**: https://github.com/radinshayanfar/voice-gender-changer

**License**: MIT

---

# PSOLA - Specifications

| Metric | Value | Status |
|--------|-------|--------|
| **Memory (C)** | <500KB | âœ… Excellent |
| **Memory (Python)** | ~2-5MB | âœ… Good |
| **Latency** | 10-30ms | âœ… Very fast |
| **RTF** | 0.1-0.2 | âœ… Fastest |
| **Quality (MOS)** | 2.8-3.5 | âš ï¸ Moderate |
| **Platform** | Cross-platform | âœ… |

---

# PSOLA - How It Works

## Time-Domain Pitch Shifting

**1. Pitch Mark Detection**:
- Find glottal closure instants (GCIs)
- Locate pitch periods

**2. Grain Extraction**:
- Extract pitch-synchronous windows
- Apply Hanning window

**3. Overlap-Add**:
- Closer spacing â†’ Higher pitch (M2F)
- Wider spacing â†’ Lower pitch (F2M)

---

# PSOLA - Advantages

## âœ… Strengths

1. **Lightweight**: <500KB implementation
2. **Very Fast**: 10Ã— faster than WORLD
3. **Simple**: Easy to implement
4. **Low Latency**: <30ms
5. **No Training**: Immediate use
6. **Efficient**: Minimal CPU usage

---

# PSOLA - Disadvantages

## âš ï¸ Limitations

1. **F0 Only**: Cannot modify formants
2. **Lower Quality**: Chipmunk effect for M2F
3. **Artifacts**: Phasiness, roughness
4. **Limited Range**: Degrades with large shifts (>6 semitones)
5. **Pitch Detection**: Can be unreliable
6. **Not Production-Grade**: Requires formant shifting for natural conversion

**Note**: PSOLA alone is insufficient for natural gender conversion

---

# DSP Comparison

| Feature | WORLD Vocoder | PSOLA |
|---------|---------------|-------|
| **Memory** | ~1MB | <500KB |
| **Latency** | 50-150ms | 10-30ms |
| **Quality** | â­â­â­â­ | â­â­â­ |
| **F0 Modification** | âœ… Excellent | âœ… Good |
| **Formant Shift** | âœ… Yes | âŒ No |
| **Artifacts** | Low | Moderate |
| **Use Case** | Production | Prototyping |

**Winner**: **WORLD Vocoder** for production quality

---

# ASPECT 2: ML/DL Edge Deployment
## Neural Networks with â‰¤2MB Constraint

---

# ML Edge Overview

## Challenge: Neural Networks on Edge Devices

**Typical VC Model**:
- Size: 50-200MB (FP32)
- GPU Memory: 2-16GB
- Inference: 100-800ms

**Target Constraint**:
- Size: â‰¤2MB (40-100Ã— reduction!)
- CPU-only: No GPU
- Latency: <100ms

**Solution**: Model compression techniques

---

# Compression Techniques

## Four Main Approaches

1. **Quantization**: FP32 â†’ INT8 (4Ã— reduction)
2. **Pruning**: Remove unnecessary weights (2-5Ã— reduction)
3. **Knowledge Distillation**: Train small model from large (5-10Ã— reduction)
4. **Architecture Design**: Lightweight networks (2-5Ã— reduction)

**Combined**: 20-100Ã— total reduction possible

---

# Quantization Deep Dive

## FP32 â†’ INT8 Conversion

**Precision Comparison**:

| Type | Bytes | Range | Use Case |
|------|-------|-------|----------|
| FP32 | 4 | Â±3.4Ã—10Â³â¸ | Training |
| FP16 | 2 | Â±65,504 | GPU inference |
| INT8 | 1 | -128 to 127 | **Edge inference** |

**Quantization**: 1M parameters = 4MB (FP32) â†’ 1MB (INT8)

---

# Quantization Methods

## Post-Training vs Quantization-Aware

**Post-Training Quantization (PTQ)**:
- âœ… Fast (no retraining)
- âš ï¸ Accuracy loss: ~5%

**Quantization-Aware Training (QAT)**:
- âœ… Better accuracy (<2% loss)
- âš ï¸ Requires retraining (10 epochs)

**Recommendation**: QAT for production

---

# Model 3: TinyVC

## Lightweight Voice Conversion

**Description**: Purpose-built architecture for edge deployment

**Repository**: https://github.com/uthree/tinyvc

**License**: MIT

---

# TinyVC - Specifications

| Metric | Value | Status |
|--------|-------|--------|
| **Memory (FP32)** | ~7MB | âŒ Too large |
| **Memory (INT8)** | **~1.8MB** | âœ… Target met! |
| **Latency** | 30-50ms | âœ… Real-time |
| **RTF** | 0.4-0.6 | âœ… Fast |
| **Quality (MOS)** | 3.8-4.2 | âœ… Excellent |
| **Platform** | CPU-optimized | âœ… |

---

# TinyVC - Architecture

## Lightweight Design

**Components**:
1. **Encoder**: Depthwise separable convolutions (128 channels)
2. **Bottleneck**: 64-dim latent space
3. **Decoder**: Inverted residual blocks
4. **Vocoder**: MelGAN-tiny

**Key Optimizations**:
- Depthwise separable convs (8Ã— fewer parameters)
- Inverted residuals (efficient)
- Squeeze-and-Excitation blocks (channel attention)

---

# TinyVC - Advantages

## âœ… Strengths

1. **Compact**: 1.8MB (INT8) meets 2MB target
2. **High Quality**: MOS 3.8-4.2 (better than DSP)
3. **Fast**: 30-50ms latency
4. **Purpose-Built**: Designed for edge
5. **Modern Architecture**: Efficient conv blocks
6. **Production-Ready**: Quantization pipeline included

---

# TinyVC - Disadvantages

## âš ï¸ Limitations

1. **Training Required**: Needs paired data
2. **Fixed Speakers**: Cannot do zero-shot
3. **Quantization Effort**: Requires QAT for best results
4. **Deployment Complexity**: ONNX/TFLite conversion
5. **Data Dependent**: Quality depends on training data
6. **Not Universal**: Trained for specific voice pairs

---

# Model 4: LLVC

## Low-Latency Voice Conversion

**Description**: Research architecture for real-time streaming (<20ms)

**Paper**: "Low-latency Real-time Voice Conversion on CPU" (arXiv:2311.00873, 2023)

**License**: Research (implementation varies)

---

# LLVC - Specifications

| Metric | Value | Status |
|--------|-------|--------|
| **Memory (INT8)** | **~2MB** | âœ… Target met! |
| **Latency** | **10-20ms** | âœ… Ultra-low! |
| **RTF** | 0.05-0.10 | âœ… Very fast |
| **Quality (MOS)** | 3.9 | âœ… Excellent |
| **Platform** | CPU streaming | âœ… |

---

# LLVC - Architecture

## Streaming Design

**Key Innovations**:
1. **Causal Convolutions**: No future context
2. **Chunk-Based**: 30ms chunks (480 samples @ 16kHz)
3. **Lightweight GRU**: Temporal modeling
4. **State Buffers**: Maintain context across chunks

**Result**: <20ms latency for real-time streaming

---

# LLVC - Advantages

## âœ… Strengths

1. **Ultra-Low Latency**: 10-20ms (best in class)
2. **Streaming**: Real-time chunk processing
3. **Compact**: ~2MB quantized
4. **CPU-Optimized**: Efficient inference
5. **Causal**: No look-ahead delay
6. **High Quality**: MOS 3.9

---

# LLVC - Disadvantages

## âš ï¸ Limitations

1. **Research Stage**: Limited public implementations
2. **Training Complexity**: Requires streaming-aware training
3. **Fixed Chunk Size**: 30ms chunks (rigid)
4. **State Management**: Complex for deployment
5. **Quality Trade-off**: Slightly lower than non-streaming
6. **Limited Availability**: Fewer pretrained models

---

# ML Edge Comparison

| Feature | TinyVC | LLVC |
|---------|--------|------|
| **Memory (INT8)** | 1.8MB | 2MB |
| **Latency** | 30-50ms | 10-20ms |
| **Quality** | â­â­â­â­ | â­â­â­â­ |
| **Streaming** | âŒ Batch | âœ… Real-time |
| **Availability** | âœ… Public | âš ï¸ Research |
| **Training** | Standard | Streaming-aware |
| **Use Case** | General VC | Real-time apps |

**TinyVC**: Production-ready, general purpose
**LLVC**: Research, ultra-low latency streaming

---

# Edge Deployment: Complete Comparison

| Method | Memory | Latency | Quality | Training | Use Case |
|--------|--------|---------|---------|----------|----------|
| **WORLD** | 1MB | 50-150ms | â­â­â­ | None | âœ… Recommended |
| **PSOLA** | 500KB | 10-30ms | â­â­ | None | Prototyping |
| **TinyVC** | 1.8MB | 30-50ms | â­â­â­â­ | Yes | High quality |
| **LLVC** | 2MB | 10-20ms | â­â­â­â­ | Yes | Streaming |

**Best Overall**: **WORLD** (no training) or **TinyVC** (with training)

---

# ASPECT 3: GPU Server State-of-the-Art
## Deep Learning for Maximum Quality

---

# GPU Server Overview

## High-Quality Voice Conversion

**Target**:
- Quality: MOS 4+ (near-human)
- Latency: 50-800ms (acceptable for server)
- GPU Memory: 2-16GB
- Model Size: 50MB-1GB

**Trade-off**: Size/compute for quality

---

# 9 GPU Models Covered

| Model | Key Feature | Quality |
|-------|-------------|---------|
| GPT-SoVITS | Best quality, few-shot | â­â­â­â­â­ |
| RVC | Real-time, retrieval | â­â­â­â­â­ |
| SoftVC VITS | Singing voice | â­â­â­â­â­ |
| Seed-VC | Lowest latency | â­â­â­â­ |
| FreeVC | Zero-shot | â­â­â­â­ |
| DDSP-SVC | Hybrid DSP+ML | â­â­â­â­ |
| kNN-VC | CPU-compatible | â­â­â­â­ |
| VITS | Multi-speaker TTS | â­â­â­â­ |
| Kaldi | Traditional ASR | â­â­â­ |

---

# Model 5: GPT-SoVITS â­

## State-of-the-Art Quality

**Description**: GPT-based prosody modeling + SoVITS conversion

**Repository**: https://github.com/RVC-Boss/GPT-SoVITS

**License**: MIT

---

# GPT-SoVITS - Specifications

| Metric | Value | Status |
|--------|-------|--------|
| **Model Size** | 500MB-1GB | Large |
| **GPU Memory** | 6-12GB | RTX 3060+ |
| **Latency** | 300-800ms | Acceptable |
| **Quality (MOS)** | **4.6/5.0** | âœ… Best! |
| **Training Data** | 5s-1min (few-shot) | âœ… Minimal! |
| **Zero-Shot** | âœ… Yes | âœ… |

---

# GPT-SoVITS - Architecture

## Two-Stage Process

**Stage 1: GPT Prosody Modeling**
- Extract prosody from reference
- Generate prosody sequence
- Transformer-based

**Stage 2: SoVITS Conversion**
- Mel-spectrogram conversion
- Flow-based generation
- HiFi-GAN vocoder

**Result**: Natural prosody + high-quality voice

---

# GPT-SoVITS - Advantages

## âœ… Strengths

1. **Highest Quality**: MOS 4.6/5.0 (state-of-the-art)
2. **Few-Shot**: 5s-1min training data
3. **Cross-Lingual**: Supports multiple languages
4. **Production API**: Built-in REST API
5. **WebUI**: Easy testing interface
6. **Active Development**: Regular updates
7. **Zero-Shot Capable**: Any-to-any conversion

---

# GPT-SoVITS - Disadvantages

## âš ï¸ Limitations

1. **Large Model**: 500MB-1GB size
2. **High GPU Memory**: 6-12GB VRAM required
3. **High Latency**: 300-800ms (not real-time)
4. **Computational Cost**: Expensive inference
5. **Complex Setup**: Multiple components
6. **Resource Intensive**: High power consumption

**Use Case**: Batch processing, high-quality production

---

# Model 6: RVC

## Retrieval-based Voice Conversion

**Description**: Retrieval mechanism + VITS for real-time conversion

**Repository**: https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI

**License**: MIT

---

# RVC - Specifications

| Metric | Value | Status |
|--------|-------|--------|
| **Model Size** | 50-200MB | Moderate |
| **GPU Memory** | 2-6GB | GTX 1660+ |
| **Latency** | **100-300ms** | âœ… Real-time! |
| **Quality (MOS)** | 4.5/5.0 | âœ… Excellent |
| **Training Data** | 10+ minutes | Reasonable |
| **Zero-Shot** | âŒ No | Few-shot only |

---

# RVC - Architecture

## Retrieval Mechanism

**Key Innovation**: Retrieval-based timbre matching

**Components**:
1. **Content Encoder**: Extract linguistic features (HuBERT)
2. **Retrieval Index**: Match similar voice characteristics
3. **VITS Decoder**: Generate mel-spectrogram
4. **Vocoder**: NSF-HiFiGAN

**Benefit**: Better timbre preservation

---

# RVC - Advantages

## âœ… Strengths

1. **Real-Time**: 100-300ms latency
2. **Excellent Quality**: MOS 4.5/5.0
3. **Retrieval**: Better timbre matching
4. **User-Friendly**: WebUI included
5. **Active Community**: Large user base
6. **Moderate GPU**: GTX 1660+ sufficient
7. **Production-Ready**: Stable and tested

---

# RVC - Disadvantages

## âš ï¸ Limitations

1. **Training Required**: 10+ minutes per speaker
2. **Not Zero-Shot**: Cannot convert unseen speakers
3. **Index Building**: Requires retrieval index creation
4. **Storage**: Index files add overhead
5. **GPU Required**: Not CPU-compatible
6. **Quality Depends on Training**: Need good data

**Use Case**: Real-time server with known speakers

---

# Model 7: SoftVC VITS

## Singing Voice Conversion Specialist

**Description**: Soft-VC content encoder + VITS for singing

**Repository**: https://github.com/svc-develop-team/so-vits-svc

**License**: **AGPL-3.0** âš ï¸ (Copyleft)

---

# SoftVC VITS - Specifications

| Metric | Value | Status |
|--------|-------|--------|
| **Model Size** | 40-100MB | Moderate |
| **GPU Memory** | 3-5GB | RTX 2060+ |
| **Latency** | 150-400ms | Real-time |
| **Quality (MOS)** | 4.5/5.0 | âœ… Excellent |
| **Training Data** | 10+ minutes | Reasonable |
| **Singing** | âœ… Optimized | âœ… Best! |

---

# SoftVC VITS - Architecture

## Singing-Specific Design

**Key Features**:
1. **Soft-VC Encoder**: Content-timbre disentanglement
2. **F0 Predictor**: Pitch contour preservation
3. **Flow-Based Generation**: High-quality mel-spec
4. **NSF-HiFiGAN**: Singing-optimized vocoder

**Specialization**: Preserves vibrato, breath, singing nuances

---

# SoftVC VITS - Advantages

## âœ… Strengths

1. **Singing Voice**: Best for singing conversion
2. **Excellent Quality**: MOS 4.5/5.0
3. **Vibrato Preservation**: Natural singing characteristics
4. **Breath Modeling**: Realistic breathing
5. **Pitch Accuracy**: Precise F0 control
6. **Mature**: Well-tested and stable

---

# SoftVC VITS - Disadvantages

## âš ï¸ Limitations

1. **AGPL-3.0 License**: Copyleft (source disclosure required)
2. **Singing-Focused**: May be suboptimal for speech
3. **Training Required**: 10+ minutes per singer
4. **GPU Required**: Not CPU-compatible
5. **Complex Setup**: Multiple components
6. **Commercial Use**: AGPL compliance required

**âš ï¸ License Warning**: Consider MIT alternatives (RVC, DDSP-SVC) for commercial use

---

# Model 8: Seed-VC

## Ultra-Low Latency

**Description**: DiT (Diffusion Transformer) architecture for speed

**Repository**: https://github.com/Plachtaa/seed-vc

**License**: MIT

---

# Seed-VC - Specifications

| Metric | Value | Status |
|--------|-------|--------|
| **Model Size** | 50-150MB | Moderate |
| **GPU Memory** | 2-4GB | GTX 1060+ |
| **Latency** | **50-150ms** | âœ… Fastest! |
| **Quality (MOS)** | 4.2/5.0 | âœ… Good |
| **Training Data** | Zero-shot | âœ… None! |
| **Real-Time** | âœ… Yes | âœ… |

---

# Seed-VC - Architecture

## Diffusion Transformer (DiT)

**Key Innovation**: U-ViT backbone for speed

**Components**:
1. **U-ViT**: Efficient transformer architecture
2. **Diffusion**: Iterative refinement (few steps)
3. **Zero-Shot**: No speaker-specific training
4. **Fast Sampling**: Optimized for speed

**Result**: Lowest latency GPU model

---

# Seed-VC - Advantages

## âœ… Strengths

1. **Lowest Latency**: 50-150ms (fastest GPU model)
2. **Zero-Shot**: Any-to-any conversion
3. **Good Quality**: MOS 4.2/5.0
4. **Low GPU Memory**: 2-4GB VRAM
5. **Simple API**: Easy to use
6. **MIT License**: Commercial-friendly

---

# Seed-VC - Disadvantages

## âš ï¸ Limitations

1. **Quality**: Slightly lower than GPT-SoVITS/RVC
2. **Less Documentation**: Newer project
3. **Limited Features**: Focused on speed
4. **Diffusion Artifacts**: May have minor noise
5. **GPU Required**: Not CPU-compatible

**Use Case**: Low-latency server applications

---

# Model 9: DDSP-SVC

## Hybrid DSP + Deep Learning

**Description**: Differentiable DSP for singing with neural networks

**Repository**: https://github.com/yxlllc/DDSP-SVC

**License**: MIT

---

# DDSP-SVC - Specifications

| Metric | Value | Status |
|--------|-------|--------|
| **Model Size** | 50-100MB | Moderate |
| **GPU Memory** | 4-8GB | RTX 4060+ |
| **Latency** | 100-300ms | Real-time |
| **Quality (MOS)** | 4.4/5.0 | âœ… Excellent |
| **Training Data** | 10+ minutes | Reasonable |
| **Singing** | âœ… Optimized | âœ… |

---

# DDSP-SVC - Architecture

## Differentiable DSP

**Key Innovation**: Interpretable DSP + neural control

**Components**:
1. **Feature Encoder**: ContentVec/HuBERT
2. **DDSP Synthesis**: Harmonic + noise
3. **F0 Predictor**: RMVPE
4. **NSF-HiFiGAN**: Vocoder

**Benefit**: Interpretable controls (pitch, harmonics)

---

# DDSP-SVC - Advantages

## âœ… Strengths

1. **Interpretable**: Understand what model is doing
2. **Efficient**: Smaller than pure DL (hybrid)
3. **Singing-Optimized**: Excellent for music
4. **Controllable**: Direct DSP parameter control
5. **High Quality**: MOS 4.4/5.0
6. **MIT License**: Commercial-friendly

---

# DDSP-SVC - Disadvantages

## âš ï¸ Limitations

1. **Singing-Focused**: May be suboptimal for speech
2. **GPU Required**: RTX 4060+ recommended
3. **Training Required**: 10+ minutes per singer
4. **Setup Complexity**: Requires ContentVec/HuBERT
5. **Less Popular**: Smaller community

**Use Case**: Singing voice conversion with interpretability

---

# Model 10: kNN-VC â­

## CPU-Compatible Zero-Shot

**Description**: k-Nearest Neighbors regression with WavLM

**Repository**: https://github.com/bshall/knn-vc

**License**: MIT

---

# kNN-VC - Specifications

| Metric | Value | Status |
|--------|-------|--------|
| **Model Size** | ~300MB | Large |
| **CPU Memory** | 8GB RAM | Standard PC |
| **GPU Memory** | 2-4GB (optional) | Small GPU |
| **Latency (CPU)** | 300-1000ms | Acceptable |
| **Latency (GPU)** | 100ms | Fast |
| **Quality (MOS)** | 4.0/5.0 | âœ… Good |
| **Zero-Shot** | âœ… Yes | âœ… |

---

# kNN-VC - Architecture

## Non-Parametric Approach

**Key Innovation**: No training - uses WavLM features + kNN

**Components**:
1. **WavLM Encoder**: Extract features (frozen)
2. **k-NN Matching**: Find similar features
3. **Feature Regression**: Weighted average
4. **HiFi-GAN**: Vocoder adapted for WavLM

**Benefit**: No training required, works on CPU!

---

# kNN-VC - Advantages

## âœ… Strengths

1. **CPU-Compatible**: Unique among GPU models!
2. **Zero-Shot**: Any-to-any conversion
3. **No Training**: Non-parametric approach
4. **Cross-Platform**: Windows, Linux, macOS
5. **Simple**: Easy to understand
6. **MIT License**: Commercial-friendly
7. **Research Value**: Non-parametric baseline

---

# kNN-VC - Disadvantages

## âš ï¸ Limitations

1. **Slower on CPU**: 300-1000ms latency
2. **Lower Quality**: MOS 4.0 (good but not best)
3. **Large Memory**: 300MB model + WavLM
4. **Variable Latency**: Depends on k value
5. **Limited Control**: Less flexible than parametric

**Use Case**: Server without GPU, research

---

# GPU Models Summary (1/2)

| Model | Memory | Latency | Quality | Training | License |
|-------|--------|---------|---------|----------|---------|
| **GPT-SoVITS** | 500MB-1GB | 300-800ms | 4.6 | 5s-1min | MIT |
| **RVC** | 50-200MB | 100-300ms | 4.5 | 10min+ | MIT |
| **SoftVC VITS** | 40-100MB | 150-400ms | 4.5 | 10min+ | AGPL |
| **Seed-VC** | 50-150MB | **50-150ms** | 4.2 | Zero | MIT |
| **FreeVC** | 100-300MB | 200-600ms | 4.1 | Zero | MIT |

---

# GPU Models Summary (2/2)

| Model | Memory | Latency | Quality | Training | License |
|-------|--------|---------|---------|----------|---------|
| **DDSP-SVC** | 50-100MB | 100-300ms | 4.4 | 10min+ | MIT |
| **kNN-VC** | 300MB | 300ms (CPU) | 4.0 | Zero | MIT |
| **VITS** | 100-500MB | 200-500ms | 4.3 | 10min+ | MIT |
| **Kaldi** | 200MB+ | 500-1000ms | 3.8 | Hours | Apache 2.0 |

**Best Quality**: GPT-SoVITS (4.6)
**Fastest**: Seed-VC (50ms)
**CPU Option**: kNN-VC

---

# Complete Comparison
## All Approaches Side-by-Side

---

# Memory Comparison

| Approach | Model | Memory | Compression |
|----------|-------|--------|-------------|
| **DSP** | WORLD | 1MB | - |
| **DSP** | PSOLA | 500KB | - |
| **ML Edge** | TinyVC | 1.8MB | 4Ã— (INT8) |
| **ML Edge** | LLVC | 2MB | 4Ã— (INT8) |
| **GPU** | RVC | 50-200MB | - |
| **GPU** | Seed-VC | 50-150MB | - |
| **GPU** | DDSP-SVC | 50-100MB | - |
| **GPU** | SoftVC VITS | 40-100MB | - |
| **GPU** | kNN-VC | 300MB | - |
| **GPU** | GPT-SoVITS | 500MB-1GB | - |

---

# Quality Comparison

| Approach | Model | Quality (MOS) | Naturalness |
|----------|-------|---------------|-------------|
| **DSP** | PSOLA | 2.8-3.5 | Moderate |
| **DSP** | WORLD | 3.5-4.0 | Good |
| **ML Edge** | TinyVC | 3.8-4.2 | Excellent |
| **ML Edge** | LLVC | 3.9 | Excellent |
| **GPU** | kNN-VC | 4.0 | Good |
| **GPU** | FreeVC | 4.1 | Good |
| **GPU** | Seed-VC | 4.2 | Good |
| **GPU** | DDSP-SVC | 4.4 | Excellent |
| **GPU** | RVC | 4.5 | Excellent |
| **GPU** | SoftVC VITS | 4.5 | Excellent |
| **GPU** | GPT-SoVITS | **4.6** | Best |

---

# Latency Comparison

| Approach | Model | Latency | Real-Time |
|----------|-------|---------|-----------|
| **ML Edge** | LLVC | 10-20ms | âœ… Yes |
| **DSP** | PSOLA | 10-30ms | âœ… Yes |
| **ML Edge** | TinyVC | 30-50ms | âœ… Yes |
| **DSP** | WORLD | 50-150ms | âœ… Yes |
| **GPU** | Seed-VC | 50-150ms | âœ… Yes |
| **GPU** | RVC | 100-300ms | âœ… Yes |
| **GPU** | DDSP-SVC | 100-300ms | âœ… Yes |
| **GPU** | SoftVC VITS | 150-400ms | âš ï¸ Maybe |
| **GPU** | FreeVC | 200-600ms | âŒ No |
| **GPU** | kNN-VC (CPU) | 300-1000ms | âŒ No |
| **GPU** | GPT-SoVITS | 300-800ms | âŒ No |

---

# Platform Comparison

| Approach | Model | CPU | GPU | Mobile |
|----------|-------|-----|-----|--------|
| **DSP** | WORLD | âœ… | âœ… | âœ… |
| **DSP** | PSOLA | âœ… | âœ… | âœ… |
| **ML Edge** | TinyVC | âœ… | âœ… | âœ… |
| **ML Edge** | LLVC | âœ… | âœ… | âœ… |
| **GPU** | kNN-VC | âœ… | âœ… | âŒ |
| **GPU** | All others | âŒ | âœ… | âŒ |

**Edge Deployment**: DSP + ML Edge
**Server Deployment**: GPU models

---

# Training Requirements

| Approach | Model | Training Data | Training Time |
|----------|-------|---------------|---------------|
| **DSP** | WORLD | None | - |
| **DSP** | PSOLA | None | - |
| **GPU** | GPT-SoVITS | 5s-1min | 1-2 hours |
| **GPU** | Seed-VC | None (zero-shot) | - |
| **GPU** | FreeVC | None (zero-shot) | - |
| **GPU** | kNN-VC | None | - |
| **GPU** | RVC | 10min+ | 2-4 hours |
| **GPU** | SoftVC VITS | 10min+ | 4-8 hours |
| **GPU** | DDSP-SVC | 10min+ | 4-8 hours |
| **ML Edge** | TinyVC | Hours | 1-3 days |
| **ML Edge** | LLVC | Hours | 2-5 days |

---

# Recommendations by Use Case

---

# Use Case 1: Mobile App

## Real-Time Voice Changer on Phone

**Recommendation**: **WORLD Vocoder** or **TinyVC**

**Why**:
- âœ… <2MB memory footprint
- âœ… CPU-only (no GPU required)
- âœ… Real-time latency (<100ms)
- âœ… Cross-platform (iOS, Android)

**Choice**:
- **WORLD**: No training, immediate use
- **TinyVC**: Better quality, requires training

---

# Use Case 2: Cloud API (High Quality)

## Production Voice Conversion Service

**Recommendation**: **GPT-SoVITS**

**Why**:
- âœ… Best quality (MOS 4.6)
- âœ… Few-shot learning (minimal data)
- âœ… Production API included
- âœ… Scalable with Kubernetes

**Setup**: Docker + GPU + Load balancer

---

# Use Case 3: Live Streaming

## Real-Time Server for Streamers

**Recommendation**: **RVC** or **Seed-VC**

**Why**:
- âœ… Low latency (50-300ms)
- âœ… Real-time capable
- âœ… Excellent quality (4.2-4.5 MOS)
- âœ… GPU-accelerated

**Choice**:
- **RVC**: Better quality (4.5 MOS)
- **Seed-VC**: Lower latency (50ms)

---

# Use Case 4: Singing Voice

## Music/Karaoke Application

**Recommendation**: **SoftVC VITS** or **DDSP-SVC**

**Why**:
- âœ… Singing-optimized
- âœ… Vibrato/breath preservation
- âœ… High quality (4.4-4.5 MOS)
- âœ… Pitch control

**Choice**:
- **SoftVC VITS**: Best for singing (âš ï¸ AGPL)
- **DDSP-SVC**: Hybrid DSP+ML (MIT license)

---

# Use Case 5: Research/Experiments

## Academic Research or Testing

**Recommendation**: **FreeVC**, **Seed-VC**, or **kNN-VC**

**Why**:
- âœ… Zero-shot capability
- âœ… Any-to-any conversion
- âœ… No training required
- âœ… Flexible experimentation

**Choice**:
- **kNN-VC**: CPU-compatible, non-parametric
- **FreeVC**: Standard baseline
- **Seed-VC**: Fast zero-shot

---

# Use Case 6: Server Without GPU

## CPU-Only Server Deployment

**Recommendation**: **kNN-VC**

**Why**:
- âœ… Works on CPU (unique!)
- âœ… Zero-shot capability
- âœ… Cross-platform (Linux/Windows/macOS)
- âœ… Good quality (MOS 4.0)

**Note**: Only GPU model that works on CPU

---

# Use Case 7: Embedded IoT

## Voice Conversion on Microcontroller

**Recommendation**: **WORLD Vocoder (C++)**

**Why**:
- âœ… ~1MB memory (smallest)
- âœ… Native C/C++ (efficient)
- âœ… No training required
- âœ… Real-time on ARM

**Deployment**: Compile native binary

---

# Deployment Strategies

---

# Edge Deployment

## Mobile/IoT/Embedded

**Architecture**:
```
Audio Input â†’ WORLD/TinyVC â†’ Audio Output
             (on-device)
```

**Steps**:
1. Compile native binary (C++/ONNX)
2. Quantize to INT8
3. Optimize with NEON/SSE
4. Package with app

**Tools**: ONNX Runtime, TensorFlow Lite

---

# Server Deployment

## Cloud API with GPU

**Architecture**:
```
Client â†’ Load Balancer â†’ [GPU Server 1]
                        â†’ [GPU Server 2]
                        â†’ [GPU Server 3]
```

**Steps**:
1. Docker container with model
2. FastAPI/Flask REST API
3. NVIDIA GPU (CUDA)
4. Kubernetes orchestration

**Tools**: Docker, K8s, FastAPI, Nginx

---

# Hybrid Deployment

## Edge + Server Combination

**Architecture**:
```
Mobile App:
  - Preview: WORLD (edge, <1MB)
  - Final: API call to GPT-SoVITS (server)
```

**Benefits**:
- âœ… Instant preview (edge)
- âœ… High-quality final (server)
- âœ… Cost-effective

**Use Case**: Photo editing apps (preview + export)

---

# Key Takeaways

---

# Summary: 3 Aspects

## Complete Coverage

**Aspect 1 - DSP (Edge)**:
- WORLD: â­â­â­â­â­ (Best edge choice)
- PSOLA: â­â­â­ (Prototyping)

**Aspect 2 - ML Edge (â‰¤2MB)**:
- TinyVC: â­â­â­â­ (Production)
- LLVC: â­â­â­â­ (Streaming)

**Aspect 3 - GPU Server**:
- GPT-SoVITS: â­â­â­â­â­ (Best quality)
- RVC: â­â­â­â­â­ (Real-time)
- kNN-VC: â­â­â­â­ (CPU-compatible)

---

# Best Model by Criteria

| Criterion | Winner | Runner-Up |
|-----------|--------|-----------|
| **Quality** | GPT-SoVITS (4.6) | RVC/SoftVC (4.5) |
| **Speed** | Seed-VC (50ms) | RVC (100ms) |
| **Compact** | PSOLA (500KB) | WORLD (1MB) |
| **Edge** | WORLD | TinyVC |
| **Server** | GPT-SoVITS | RVC |
| **Singing** | SoftVC VITS | DDSP-SVC |
| **CPU** | kNN-VC | WORLD |
| **Zero-Shot** | GPT-SoVITS | Seed-VC |
| **Real-Time** | Seed-VC | RVC |

---

# License Considerations

## Open Source Licenses

**Permissive (8/10 GPU models)**:
- âœ… MIT: GPT-SoVITS, RVC, Seed-VC, DDSP-SVC, kNN-VC, FreeVC, VITS
- âœ… BSD-3-Clause: WORLD
- âœ… Apache 2.0: Kaldi

**Copyleft (1/10)**:
- âš ï¸ AGPL-3.0: SoftVC VITS (requires source disclosure)

**Recommendation**: Use MIT-licensed alternatives for commercial products

---

# Quality vs. Size Trade-off

## Visual Summary

```
Quality (MOS)
    â†‘
4.6 â”‚         â— GPT-SoVITS (500MB-1GB)
4.5 â”‚       â— RVC, SoftVC (50-200MB)
4.4 â”‚     â— DDSP-SVC (50-100MB)
4.2 â”‚   â— Seed-VC (50-150MB)
4.0 â”‚ â— TinyVC (1.8MB)
3.8 â”‚â— WORLD (1MB)
3.0 â”‚â— PSOLA (500KB)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
      Size
```

**Insight**: 50-100Ã— size increase for ~20% quality gain

---

# Speed vs. Quality Trade-off

## Visual Summary

```
Quality (MOS)
    â†‘
4.6 â”‚â— GPT-SoVITS (300-800ms)
4.5 â”‚  â— RVC (100-300ms)
4.4 â”‚    â— DDSP-SVC (100-300ms)
4.2 â”‚      â— Seed-VC (50-150ms)
4.0 â”‚        â— TinyVC (30-50ms)
3.8 â”‚          â— WORLD (50-150ms)
3.0 â”‚            â— PSOLA (10-30ms)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
      Latency
```

**Insight**: Fast models sacrifice quality

---

# Implementation Roadmap

## Week 1-2: Edge (WORLD)
1. Install WORLD vocoder
2. Test M2F/F2M conversion
3. Measure performance
4. Deploy to edge device

## Week 3-4: ML Edge (TinyVC)
1. Train TinyVC model
2. Apply INT8 quantization
3. Export to ONNX
4. Deploy to mobile

## Week 5-6: GPU Server (GPT-SoVITS/RVC)
1. Setup GPU server
2. Install model
3. Create REST API
4. Load testing

---

# Future Directions

## Emerging Trends

1. **Unified Models**: Single model for all speakers
2. **Real-Time Quality**: GPT-SoVITS-level quality at 50ms
3. **Smaller Models**: 1GB â†’ 10MB without quality loss
4. **Multimodal**: Audio + video (lip sync)
5. **Edge AI**: On-device GPT-level models
6. **Zero-Shot Everything**: No training for any speaker

**Timeline**: 2-5 years

---

# Resources

## Documentation

- ðŸ“š **DSP Literature**: 53KB, WORLD + PSOLA deep dive
- ðŸ“š **ML Edge Literature**: 47KB, Quantization + TinyVC
- ðŸ“š **GPU Server Literature**: 162KB, All 9 models
- ðŸ“‹ **GitHub Repositories**: Curated list with setup
- ðŸ§ª **Testing Framework**: Actual benchmarks
- ðŸ“„ **Licensing Guide**: THIRD_PARTY_LICENSES.md

**Repository**: https://github.com/MuruganR96/VoiceConversion_Survey

---

# Academic Citations

## Key Papers

**WORLD Vocoder**:
```
Morise, M., Yokomori, F., & Ozawa, K. (2016).
WORLD: A vocoder-based high-quality speech synthesis system.
IEICE Transactions, 99(7), 1877-1884.
```

**PSOLA**:
```
Moulines, E., & Charpentier, F. (1990).
Pitch-synchronous waveform processing techniques.
Speech Communication, 9(5-6), 453-467.
```

**kNN-VC**:
```
van Niekerk, B., & Baas, M. (2023).
kNN-VC: Any-to-Any Voice Conversion. Interspeech 2023.
```

---

# Ethical Considerations

## Responsible AI

**âœ… Allowed Uses**:
- Personal voice assistants
- Accessibility tools (speech impairment)
- Entertainment (with disclosure)
- Academic research

**âŒ Prohibited Uses**:
- Deepfakes without consent
- Fraud or impersonation
- Bypassing voice authentication
- Political misinformation

**Rule**: Always obtain consent before voice cloning

---

# Conclusion

## Complete Voice Conversion Solution

**Edge Deployment**: âœ… WORLD, TinyVC (<2MB)
**Server Deployment**: âœ… 9 GPU models (GPT-SoVITS best)
**All Use Cases Covered**: âœ… Mobile to Cloud

**Total Documentation**:
- 262KB literature (37,500 words)
- 140KB+ deployment guides
- Working implementations
- Production-ready

**Status**: Complete, production-ready resource

---

# Thank You

## Questions?

**Repository**: https://github.com/MuruganR96/VoiceConversion_Survey

**Contact**: Murugan R

**Documentation Includes**:
- 3 comprehensive literature documents (155 pages)
- Complete model comparison
- Deployment guides
- Working code examples
- License information

**All models, all approaches, all deployment scenarios covered**

---

# Appendix

## Additional Resources

---

# Appendix A: GPU Requirements

| GPU Model | VRAM | Suitable For |
|-----------|------|--------------|
| GTX 1060 | 6GB | Seed-VC (minimal) |
| GTX 1660 | 6GB | RVC (recommended) |
| RTX 2060 | 6GB | SoftVC VITS, FreeVC |
| RTX 3060 | 12GB | GPT-SoVITS (minimal) |
| RTX 3090 | 24GB | All models (production) |
| RTX 4090 | 24GB | All models (best) |

**Budget Option**: GTX 1660 for RVC
**Production**: RTX 3090/4090

---

# Appendix B: Cost Comparison

## Cloud GPU Pricing (AWS)

| Instance | GPU | VRAM | Price/Hour |
|----------|-----|------|------------|
| g4dn.xlarge | T4 | 16GB | $0.526 |
| g5.xlarge | A10G | 24GB | $1.006 |
| p3.2xlarge | V100 | 16GB | $3.06 |
| g5.12xlarge | 4Ã—A10G | 96GB | $5.672 |

**Monthly (24/7)**: $378 - $4,083

**Cost-Effective**: Spot instances (50-70% discount)

---

# Appendix C: Quantization Impact

## Quality Loss from INT8

| Model | FP32 MOS | INT8 MOS | Loss |
|-------|----------|----------|------|
| TinyVC | 4.1 | 3.9 | -0.2 |
| LLVC | 4.0 | 3.9 | -0.1 |
| RVC | 4.5 | 4.3 | -0.2 |
| GPT-SoVITS | 4.6 | 4.4 | -0.2 |

**Typical**: <5% quality loss with QAT

---

# Appendix D: Training Data Requirements

## Minimum Audio Duration

| Model | Min Duration | Recommended | Quality |
|-------|--------------|-------------|---------|
| GPT-SoVITS | 5 seconds | 30-60s | Excellent |
| RVC | 10 minutes | 30min+ | Excellent |
| SoftVC VITS | 10 minutes | 1 hour+ | Best |
| DDSP-SVC | 10 minutes | 30min+ | Excellent |
| TinyVC | 1 hour | 5 hours+ | Good |

**Audio Quality**: Studio-quality preferred (clean, no noise)

---

# Appendix E: Platform Support

| Platform | WORLD | TinyVC | GPU Models |
|----------|-------|--------|------------|
| Windows | âœ… | âœ… | âœ… |
| Linux | âœ… | âœ… | âœ… |
| macOS | âœ… | âœ… | âš ï¸ (No CUDA) |
| iOS | âœ… | âœ… | âŒ |
| Android | âœ… | âœ… | âŒ |
| Embedded | âœ… | âš ï¸ | âŒ |

**Mobile**: Edge models only (DSP + ML Edge)
**Server**: GPU models require NVIDIA GPU (Linux/Windows)

---

# End of Presentation

**Total Slides**: 100+

**Comprehensive Coverage**: All aspects, all models, all metrics

**Ready for**: Academic presentations, technical reviews, business proposals

**Next Steps**: Choose deployment scenario and implement
