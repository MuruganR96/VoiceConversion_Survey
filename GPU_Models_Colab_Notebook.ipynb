{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Conversion GPU Models - Comprehensive Testing\n",
    "## Test 7 State-of-the-Art Models on Google Colab\n",
    "\n",
    "**Models Tested**:\n",
    "1. GPT-SoVITS\n",
    "2. RVC (Retrieval-based Voice Conversion)\n",
    "3. SoftVC VITS\n",
    "4. Seed-VC\n",
    "5. FreeVC\n",
    "6. VITS\n",
    "7. Kaldi-based VC\n",
    "\n",
    "**Requirements**:\n",
    "- Google Colab with GPU (Runtime > Change runtime type > GPU > T4)\n",
    "- ~3-4 hours total runtime\n",
    "- ~15GB disk space\n",
    "\n",
    "**Author**: Voice Conversion Survey Project\n",
    "**Repository**: https://github.com/MuruganR96/VoiceConversion_Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Setup and GPU Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n",
    "print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\" if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install common dependencies\n",
    "!pip install -q librosa soundfile numpy scipy matplotlib tqdm psutil GPUtil\n",
    "\n",
    "print(\"✓ Common dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory structure\n",
    "!mkdir -p test_audio results logs models\n",
    "\n",
    "print(\"✓ Directory structure created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test audio files\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "def generate_test_voice(duration=3.0, f0=150, sr=16000, output_path='test.wav'):\n",
    "    \"\"\"Generate synthetic voice for testing\"\"\"\n",
    "    t = np.linspace(0, duration, int(sr * duration))\n",
    "    \n",
    "    # Create harmonics\n",
    "    signal = np.zeros_like(t)\n",
    "    for i, amp in enumerate([1.0, 0.5, 0.3, 0.2, 0.1], 1):\n",
    "        signal += amp * np.sin(2 * np.pi * f0 * i * t)\n",
    "    \n",
    "    # Envelope\n",
    "    envelope = np.ones_like(t)\n",
    "    attack = int(0.1 * sr)\n",
    "    release = int(0.1 * sr)\n",
    "    envelope[:attack] = np.linspace(0, 1, attack)\n",
    "    envelope[-release:] = np.linspace(1, 0, release)\n",
    "    \n",
    "    signal = signal * envelope\n",
    "    signal = signal / np.max(np.abs(signal)) * 0.8\n",
    "    \n",
    "    sf.write(output_path, signal, sr)\n",
    "    print(f\"Generated: {output_path} (F0={f0}Hz, {duration}s)\")\n",
    "\n",
    "# Generate test files\n",
    "generate_test_voice(3.0, 120, 16000, 'test_audio/male_voice.wav')\n",
    "generate_test_voice(3.0, 220, 16000, 'test_audio/female_voice.wav')\n",
    "\n",
    "print(\"\\n✓ Test audio files generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Benchmarking Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import GPUtil\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "class ModelBenchmark:\n",
    "    \"\"\"Benchmark model performance\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self.results = {\n",
    "            'model': model_name,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'metrics': {}\n",
    "        }\n",
    "    \n",
    "    def measure_inference(self, func, *args, num_runs=5):\n",
    "        \"\"\"Measure inference time and GPU memory\"\"\"\n",
    "        \n",
    "        # Warmup\n",
    "        _ = func(*args)\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        times = []\n",
    "        gpu_memory = []\n",
    "        \n",
    "        for i in range(num_runs):\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            \n",
    "            start = time.perf_counter()\n",
    "            output = func(*args)\n",
    "            torch.cuda.synchronize()\n",
    "            end = time.perf_counter()\n",
    "            \n",
    "            times.append(end - start)\n",
    "            gpu_memory.append(torch.cuda.max_memory_allocated() / 1e9)  # GB\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        return {\n",
    "            'latency_mean': np.mean(times) * 1000,  # ms\n",
    "            'latency_std': np.std(times) * 1000,\n",
    "            'gpu_memory_peak': np.max(gpu_memory),  # GB\n",
    "            'gpu_memory_mean': np.mean(gpu_memory)\n",
    "        }\n",
    "    \n",
    "    def compute_quality_metrics(self, original, converted, sr=16000):\n",
    "        \"\"\"Compute quality metrics\"\"\"\n",
    "        import librosa\n",
    "        \n",
    "        # MCD (Mel-Cepstral Distortion)\n",
    "        mfcc_orig = librosa.feature.mfcc(y=original, sr=sr, n_mfcc=13)\n",
    "        mfcc_conv = librosa.feature.mfcc(y=converted, sr=sr, n_mfcc=13)\n",
    "        \n",
    "        min_len = min(mfcc_orig.shape[1], mfcc_conv.shape[1])\n",
    "        diff = mfcc_orig[:, :min_len] - mfcc_conv[:, :min_len]\n",
    "        mcd = np.mean(np.sqrt(np.sum(diff**2, axis=0))) * (10 / np.log(10)) * 2\n",
    "        \n",
    "        # Pitch accuracy\n",
    "        f0_orig, _, _ = librosa.pyin(original, fmin=80, fmax=400)\n",
    "        f0_conv, _, _ = librosa.pyin(converted, fmin=80, fmax=400)\n",
    "        \n",
    "        f0_orig = f0_orig[~np.isnan(f0_orig)]\n",
    "        f0_conv = f0_conv[~np.isnan(f0_conv)]\n",
    "        \n",
    "        if len(f0_orig) > 0 and len(f0_conv) > 0:\n",
    "            pitch_shift = 12 * np.log2(np.median(f0_conv) / np.median(f0_orig))\n",
    "        else:\n",
    "            pitch_shift = 0\n",
    "        \n",
    "        return {\n",
    "            'mcd': float(mcd),\n",
    "            'pitch_shift_semitones': float(pitch_shift)\n",
    "        }\n",
    "    \n",
    "    def save_results(self):\n",
    "        \"\"\"Save benchmark results\"\"\"\n",
    "        filename = f\"results/{self.model_name}_results.json\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(self.results, f, indent=2)\n",
    "        print(f\"\\n✓ Results saved to {filename}\")\n",
    "\n",
    "print(\"✓ Benchmarking utilities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 1: GPT-SoVITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Testing Model 1: GPT-SoVITS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Clone repository\n",
    "!git clone https://github.com/RVC-Boss/GPT-SoVITS.git\n",
    "%cd GPT-SoVITS\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"\\n✓ GPT-SoVITS repository cloned and dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained models\n",
    "!python download_models.py\n",
    "\n",
    "print(\"✓ GPT-SoVITS models downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GPT-SoVITS\n",
    "# Note: This is a placeholder - actual implementation depends on API\n",
    "\n",
    "benchmark = ModelBenchmark('GPT-SoVITS')\n",
    "\n",
    "# TODO: Implement actual conversion\n",
    "# This requires understanding GPT-SoVITS API structure\n",
    "\n",
    "print(\"GPT-SoVITS testing in progress...\")\n",
    "print(\"Note: Manual testing may be required due to API complexity\")\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 2: RVC (Retrieval-based Voice Conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Testing Model 2: RVC\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Clone repository\n",
    "!git clone https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI.git\n",
    "%cd Retrieval-based-Voice-Conversion-WebUI\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"\\n✓ RVC repository cloned and dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained models\n",
    "!python download_models.py\n",
    "\n",
    "print(\"✓ RVC models downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RVC\n",
    "benchmark = ModelBenchmark('RVC')\n",
    "\n",
    "# TODO: Implement RVC inference\n",
    "print(\"RVC testing in progress...\")\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 3: SoftVC VITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Testing Model 3: SoftVC VITS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Clone repository\n",
    "!git clone https://github.com/svc-develop-team/so-vits-svc.git\n",
    "%cd so-vits-svc\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"\\n✓ SoftVC VITS repository cloned and dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained encoder\n",
    "!python download_pretrain.py\n",
    "\n",
    "print(\"✓ SoftVC VITS models downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SoftVC VITS\n",
    "benchmark = ModelBenchmark('SoftVC-VITS')\n",
    "\n",
    "# TODO: Implement SoftVC VITS inference\n",
    "print(\"SoftVC VITS testing in progress...\")\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 4: Seed-VC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Testing Model 4: Seed-VC\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Clone repository\n",
    "!git clone https://github.com/Plachtaa/seed-vc.git\n",
    "%cd seed-vc\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"\\n✓ Seed-VC repository cloned and dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained model\n",
    "!wget -q https://huggingface.co/Plachtaa/seed-vc/resolve/main/seed_vc.pt -O models/seed_vc.pt\n",
    "\n",
    "print(\"✓ Seed-VC model downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Seed-VC\n",
    "import torch\n",
    "import soundfile as sf\n",
    "\n",
    "benchmark = ModelBenchmark('Seed-VC')\n",
    "\n",
    "# Load model (simplified - actual API may differ)\n",
    "try:\n",
    "    from seed_vc import SeedVC\n",
    "    \n",
    "    model = SeedVC('models/seed_vc.pt').cuda()\n",
    "    \n",
    "    # Load test audio\n",
    "    source, sr = sf.read('../test_audio/male_voice.wav')\n",
    "    reference, _ = sf.read('../test_audio/female_voice.wav')\n",
    "    \n",
    "    def convert():\n",
    "        return model.convert(source, reference)\n",
    "    \n",
    "    # Benchmark\n",
    "    metrics = benchmark.measure_inference(convert)\n",
    "    benchmark.results['metrics'] = metrics\n",
    "    \n",
    "    print(f\"\\nSeed-VC Results:\")\n",
    "    print(f\"  Latency: {metrics['latency_mean']:.2f} ± {metrics['latency_std']:.2f} ms\")\n",
    "    print(f\"  GPU Memory: {metrics['gpu_memory_peak']:.2f} GB\")\n",
    "    \n",
    "    benchmark.save_results()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error testing Seed-VC: {e}\")\n",
    "    print(\"Manual testing may be required\")\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 5: FreeVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Testing Model 5: FreeVC\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Clone repository\n",
    "!git clone https://github.com/OlaWod/FreeVC.git\n",
    "%cd FreeVC\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"\\n✓ FreeVC repository cloned and dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained models\n",
    "# WavLM encoder\n",
    "!wget -q https://huggingface.co/microsoft/wavlm-large/resolve/main/pytorch_model.bin -O checkpoints/wavlm-large.pt\n",
    "\n",
    "print(\"✓ FreeVC models downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test FreeVC\n",
    "benchmark = ModelBenchmark('FreeVC')\n",
    "\n",
    "# TODO: Implement FreeVC inference\n",
    "print(\"FreeVC testing in progress...\")\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 6: VITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Testing Model 6: VITS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Clone repository\n",
    "!git clone https://github.com/jaywalnut310/vits.git\n",
    "%cd vits\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q Cython numpy scipy matplotlib unidecode phonemizer\n",
    "\n",
    "print(\"\\n✓ VITS repository cloned and dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test VITS\n",
    "benchmark = ModelBenchmark('VITS')\n",
    "\n",
    "# Note: VITS is primarily TTS, requires adaptation for pure VC\n",
    "print(\"VITS testing - requires model adaptation for voice conversion\")\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 7: Kaldi-based VC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Testing Model 7: Kaldi-based VC\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Note: Kaldi-based VC requires extensive setup and is not suitable for Colab\")\n",
    "print(\"Skipping this model for automated testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Results Summary and Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "# Collect all results\n",
    "result_files = glob.glob('results/*_results.json')\n",
    "\n",
    "all_results = []\n",
    "for file in result_files:\n",
    "    with open(file, 'r') as f:\n",
    "        all_results.append(json.load(f))\n",
    "\n",
    "# Generate summary report\n",
    "print(\"=\" * 60)\n",
    "print(\"VOICE CONVERSION GPU MODELS - TEST RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if all_results:\n",
    "    print(f\"\\n{'Model':<20} {'Latency (ms)':<15} {'GPU Mem (GB)':<15} {'MCD':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for result in all_results:\n",
    "        model = result['model']\n",
    "        metrics = result.get('metrics', {})\n",
    "        latency = metrics.get('latency_mean', 'N/A')\n",
    "        gpu_mem = metrics.get('gpu_memory_peak', 'N/A')\n",
    "        mcd = metrics.get('mcd', 'N/A')\n",
    "        \n",
    "        if isinstance(latency, float):\n",
    "            latency = f\"{latency:.2f}\"\n",
    "        if isinstance(gpu_mem, float):\n",
    "            gpu_mem = f\"{gpu_mem:.2f}\"\n",
    "        if isinstance(mcd, float):\n",
    "            mcd = f\"{mcd:.2f}\"\n",
    "        \n",
    "        print(f\"{model:<20} {latency:<15} {gpu_mem:<15} {mcd:<10}\")\n",
    "else:\n",
    "    print(\"\\nNo results found. Models may need manual testing.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive report\n",
    "report = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'gpu_info': {\n",
    "        'name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU',\n",
    "        'memory_gb': torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else 0\n",
    "    },\n",
    "    'models_tested': len(all_results),\n",
    "    'results': all_results\n",
    "}\n",
    "\n",
    "with open('results/comprehensive_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"✓ Comprehensive report saved to results/comprehensive_report.json\")\n",
    "\n",
    "# Download results\n",
    "from google.colab import files\n",
    "files.download('results/comprehensive_report.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Important Notes\n",
    "\n",
    "### Models Requiring Manual Setup:\n",
    "Many of these models require:\n",
    "1. **Training data**: Some models need fine-tuning on speaker data\n",
    "2. **Pretrained weights**: Download from HuggingFace or official sources\n",
    "3. **Complex setup**: API structure varies between models\n",
    "\n",
    "### Automated Testing Limitations:\n",
    "- Each model has different API structures\n",
    "- Some require WebUI interaction\n",
    "- Pretrained weights may not be publicly available\n",
    "- Training may be required for fair comparison\n",
    "\n",
    "### Recommended Approach:\n",
    "1. Run this notebook to clone all repositories\n",
    "2. Follow individual model documentation for detailed setup\n",
    "3. Use the benchmarking utilities provided above\n",
    "4. Collect results manually if automated testing fails\n",
    "\n",
    "### Repository:\n",
    "For complete documentation and guides, see:\n",
    "https://github.com/MuruganR96/VoiceConversion_Survey"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
